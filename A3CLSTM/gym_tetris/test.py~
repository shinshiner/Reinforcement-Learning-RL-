from __future__ import division
import torch
import torch.nn.functional as F
from utils import setup_logger
from model import agentNET
from torch.autograd import Variable
import time
import logging
import random
import numpy as np
import sys
from env import *

def test(args, shared_model):
    log = {}
    logger = setup_logger("test_log",  "./logs/test_log")

    torch.manual_seed(args.seed)
    env = Tetris(50)

    model = agentNET()
    model.eval()

    test_time = 0

    while(1):
        model.load_state_dict(shared_model.state_dict())
        if args.gpu:
            model = model.cuda()

        if args.gpu:
            cx = Variable(torch.zeros(1, 240).cuda())
            hx = Variable(torch.zeros(1, 240).cuda())
        else:
            cx = Variable(torch.zeros(1, 240))
            hx = Variable(torch.zeros(1, 240))

        state = env.reset()#50 100 3
        state = state.tolist()
        state = torch.from_numpy(np.array([state])).float()
        #print(state.shape)
        state = state.transpose(3, 1)
        #print(state)
        #logger.info(str(state))

        while(1):
            if args.gpu:
                value, logit, (hx, cx) = model((Variable(state.cuda()),(hx, cx)))
            else:
                value, logit, (hx, cx) = model((Variable(state),(hx, cx)))

            prob = F.softmax(logit)
            if args.gpu:
                action = prob.max(1)[1].data.cpu()
            else:
                action = prob.max(1)[1].data

            state, done, reward, _ = env.step(action.numpy()[0])

            state = state.tolist()
            state = torch.from_numpy(np.array([state, ])).float()

            if done:
                test_time += 1
                break

        if test_time % 500 == 0:
            test_time = 0
            state_to_save = model.state_dict()
            torch.save(state_to_save, '{0}{1}_agent.dat'.format(args.save_model_dir, args.env))
            print('save')        
